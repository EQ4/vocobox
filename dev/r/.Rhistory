y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
lm(x~y)
lm(y~x)
data(anscombe)
example(anscombe)
data(diamond)
y <- diamond$price; x <- diamond$carat; n <- length(y)
fit <- lm(y ~ x)
e <- resid(fit)
yhat <- predict(fit)
max(abs(e -(y - yhat)))
data(diamonds)
y <- diamonds$price; x <- diamonds$carat; n <- length(y)
fit <- lm(y ~ x)
e <- resid(fit)
yhat <- predict(fit)
max(abs(e -(y - yhat)))
max(abs(e - (y - coef(fit)[1] - coef(fit)[2] * x)))
plot(diamonds$carat, e,
xlab = "Mass (carats)",
ylab = "Residuals (SIN $)",
bg = "lightblue",
col = "black", cex = 1.1, pch = 21,frame = FALSE)
abline(h = 0, lwd = 2)
for (i in 1 : n)
lines(c(x[i], x[i]), c(e[i], 0), col = "red" , lwd = 2)
;
x <- runif(100, -3, 3); y <- x + sin(x) + rnorm(100, sd = .2);
plot(x, y); abline(lm(y ~ x))
library(UsingR); data(diamond)
y <- diamond$price; x <- diamond$carat; n <- length(y)
beta1 <- cor(y, x) * sd(y) / sd(x)
beta0 <- mean(y) - beta1 * mean(x)
e <- y - beta0 - beta1 * x
sigma <- sqrt(sum(e^2) / (n-2))
ssx <- sum((x - mean(x))^2)
seBeta0 <- (1 / n + mean(x) ^ 2 / ssx) ^ .5 * sigma
seBeta1 <- sigma / sqrt(ssx)
tBeta0 <- beta0 / seBeta0; tBeta1 <- beta1 / seBeta1
pBeta0 <- 2 * pt(abs(tBeta0), df = n - 2, lower.tail = FALSE)
pBeta1 <- 2 * pt(abs(tBeta1), df = n - 2, lower.tail = FALSE)
coefTable <- rbind(c(beta0, seBeta0, tBeta0, pBeta0), c(beta1, seBeta1, tBeta1, pBeta1))
colnames(coefTable) <- c("Estimate", "Std. Error", "t value", "P(>|t|)")
rownames(coefTable) <- c("(Intercept)", "x")
coefTable
fit <- lm(y ~ x);
summary(fit)$coefficients
source('~/Dev/datasciencecoursera-repos/assignements/2-rprog-2/cachematrix.R')
source('~/Dev/datasciencecoursera-repos/assignements/3-cleaning-w3/run_analysis.R')
source('~/.active-rstudio-document')
subjectMeanVars <- dcast(sxylMeltAll, subject ~ variable, mean)
activityMeanVars <- dcast(sxylMeltAll, activity ~ variable, mean)
meanVars <- dcast(sxylMeltAll, subject+activity ~ variable, mean)
source('~/Dev/datasciencecoursera-repos/assignements/4-explo-a1/sandbox.R')
setwd("/Users/martin/Dev/datasciencecoursera-repos/assignements/4-explo-a1/")
d <- read.table("../../datasciencecoursera/data/4-exploring/household_power_consumption.txt", sep=";", header=T, na.strings="?")
setwd("/Users/martin/Dev/datasciencecoursera-repos/assignements/4-explo-a2")
library(ggplot2)
NEI <- readRDS("data/summarySCC_PM25.rds")
SCC <- readRDS("data/Source_Classification_Code.rds")
# content summary
pollutantSet <- unique(NEI$Pollutant) # 1 single pollutent
cateogrySet <- unique(NEI$SCC) # 5480 categories
typeSet <- unique(NEI$type) # "POINT"    "NONPOINT" "ON-ROAD"  "NON-ROAD"
yearSet <- unique(NEI$year) # 1999 2002 2005 2008
# emissionNa <- sum(is.na(NEI$Emissions)) # 0 missing values
-------------------------------------------------------------
# Have total emissions from PM2.5 decreased in the United States from 1999 to 2008?
yearTotalEmissions <- aggregate(NEI$Emissions ~ NEI$year, NEI, sum) # slow!
# Using the base plotting system, make a plot showing the total PM2.5 emission from
# all sources for each of the years 1999, 2002, 2005, and 2008.
plot(yearTotalEmissions, type="l",
main=expression('Total emissions of PM'[2.5]),
xlab="Time", ylab="Total emissions"
)
yearTotalEmissions <- aggregate(NEI$Emissions ~ NEI$year, NEI, sum) # slow!
plot(yearTotalEmissions, type="l",
main=expression('Total emissions of PM'[2.5]),
xlab="Time", ylab="Total emissions"
)
select <- (NEI$fips == "24510")
n <- sum(select) # 2096
baltimore <- NEI[select,]
baltimoreYearTotalEmissions <- aggregate(Emissions ~ year, baltimore, sum)
plot(baltimoreYearTotalEmissions, type="l",
main=expression('Baltimore City, Maryland : total emissions from PM'[2.5]),
xlab="Time", ylab="Total emissions"
)
library(plyr)
yearly_emmisions <- ddply(NEI,.(year),summarise,pm25_tot_tons=sum(Emissions)/1000)
barplot(yearly_emmisions$pm25_tot_tons,names.arg=yearly_emmisions$year,
col="lightblue",
main="Year wise emission from all sources in US",
xlab="Year",
ylab=expression('PM'[2.5]*' in tons (thousands)'),
ylim=c(0,8000))
plot1<-tapply(NEI$Emission,NEI$year,sum)
# ---------------------------------------------------------------------
# Of the four types of sources indicated by the type (point, nonpoint, onroad, nonroad) variable,
baltimoreByType <- aggregate(Emissions ~ year + type, baltimore, sum)
ggplot(baltimoreByType, aes(x=year, y=Emissions, group = type, colour = type)) +
geom_line() +
geom_point() +
ggtitle(expression(atop("Total emissions per type", atop(italic("Non-point is the only type that increased from 1999 to 2008"), ""))))
# Which have seen increases in emissions from 1999â€“2008?
cci1 <- grep("coal.*comb", SCC$"Short.Name", ignore.case=T)# 10
cci2 <- grep("comb.*coal", SCC$"Short.Name", ignore.case=T)# 91
# SCC[cci2, "Short.Name"] > e.g. : "Ext Comb /Electric Gen /Anthracite Coal /Pulverized Coal"
cci3 <- grep("coal.*comb", SCC$"EI.Sector", ignore.case=T)# 0
cci4 <- grep("comb.*coal", SCC$"EI.Sector", ignore.case=T)# 99
coalCombustionIndex <- cci2
coalCombustionSccs <- SCC[coalCombustionIndex,"SCC"]
usCoalCombustionIndex <- (NEI$SCC %in% coalCombustionSccs)
usCoalCombustion <- NEI[usCoalCombustionIndex, ]
coalCombPerYear <- aggregate(Emissions ~ year, usCoalCombustion, sum)
plot.new()
plot(coalCombPerYear, type="l", main="Coal combustion PM25 emissions in United States")
vehicleMotorIndex <- grep("motor.*vehicle", SCC$"Short.Name", ignore.case=T) # reverse pattern returns no entity
sum(vehicleMotorIndex) # 59833 categories selected
vehicleMotorSccs <- SCC[vehicleMotorIndex,"SCC"]
#baltimoreVehicleMotorIndex <- (NEI$SCC %in% vehicleMotorSccs & NEI$fips == "24510")
baltimoreVehicleMotorIndex <- (NEI$type == "ON-ROAD" & NEI$fips == "24510")
baltimoreVehicleMotor <- NEI[baltimoreVehicleMotorIndex, ]
baltimoreVehicleMotorPerYear <- aggregate(Emissions ~ year, baltimoreVehicleMotor, sum)
plot.new()
plot(baltimoreVehicleMotorPerYear, type="l")
# answer : decreased from 350 to 100
# ---------------------------------------------------------------------
# Compare emissions from motor vehicle sources in Baltimore City with emissions from motor vehicle sources
# in Los Angeles County, California (fips == "06037").
laVehicleMotorIndex <- (NEI$SCC %in% vehicleMotorSccs & NEI$fips == "06037")
laVehicleMotorIndex <- (NEI$type == "ON-ROAD" & NEI$fips == "06037")
laVehicleMotor <- NEI[laVehicleMotorIndex, ]
laVehicleMotorPerYear <- aggregate(Emissions ~ year, laVehicleMotor, sum)
names(baltimoreVehicleMotorPerYear)[1] <- "year"
names(baltimoreVehicleMotorPerYear)[2] <- "emission"
names(laVehicleMotorPerYear)[1] <- "year"
names(laVehicleMotorPerYear)[2] <- "emission"
compared <- rbind(
cbind(baltimoreVehicleMotorPerYear, city=rep("Baltimore City", nrow(baltimoreVehicleMotorPerYear))),
cbind(laVehicleMotorPerYear, city=rep("Los Angeles", nrow(laVehicleMotorPerYear)))
)
ggplot(compared, aes(x=year, y=emission, group = city, colour = city)) +
geom_line() +
geom_point() +
ggtitle("Total emissions of PM25 per city")
NEI_mot_veh <- subset(NEI, type == "ON-ROAD" & fips=="24510")
plot2<-subset(NEI,fips == "24510",select=c(Emissions,year))
source('~/.active-rstudio-document', echo=TRUE)
library(ggplot2)
setwd("/Users/martin/Dev/datasciencecoursera-repos/assignements/5-represearch-a1")
activity <- read.csv("activity.csv", header=T)
# Convert interval to readable time
time0 <- sprintf("%04d", activity$interval)
activity$time <- as.factor(gsub("(\\d{2})(\\d{2})","\\1:\\2", time0))
totalStepsByDay <- aggregate(activity$steps ~ activity$date, data = activity, sum)
meanStepsByDay <- mean(totalStepsByDay[,2])
medianStepsByDay <- median(totalStepsByDay[,2])
steps <- totalStepsByDay[,2]
ggplot(totalStepsByDay, aes(x=steps)) +
geom_histogram(colour="black", fill="white", binwidth=5000) +
geom_vline(aes(xintercept=meanStepsByDay, color="Mean"), size=1, show_guide=T) +
geom_vline(aes(xintercept=medianStepsByDay, color="Median"), linetype="dashed", size=1, show_guide=T) +
guides(colour=guide_legend(title=NULL)) +
labs(title = "Total number of steps taken each day", x="Number of steps", y="Frequency")
c(meanStepsByDay=meanStepsByDay, medianStepsByDay=medianStepsByDay)
meanStepsByInterval <- aggregate(activity$steps ~ activity$time, data = activity, mean)
interval <- meanStepsByInterval[,1]
steps <- meanStepsByInterval[,2]
ggplot(meanStepsByInterval) +
geom_line(aes(y = steps, x = interval, group = 1)) +
scale_x_discrete(breaks = interval[seq(1,288, by = 6)]) +
theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
labs(title = "Average number of steps taken each day",
x="5-minute interval",
y="Average number of steps taken")
meanStepsByInterval <- aggregate(activity$steps ~ activity$time, data = activity, mean)
maxSteps <- max(meanStepsByInterval[,2])
maxActivityId <- which(meanStepsByInterval[,2] == maxSteps)
maxActivityInterval <- meanStepsByInterval[maxActivityId,1]
c(MaxActivityInterval=maxActivityInterval)
maxSteps <- max(meanStepsByInterval[,2])
meanStepsByInterval <- aggregate(activity$steps ~ activity$time, data = activity, mean)
meanStepsByInterval <- aggregate(activity$steps ~ activity$time, data = activity, max)
mean
source('~/.active-rstudio-document', echo=TRUE)
csv$PROPDMGEXPVAL <- sapply(csv, getValueFromExp)
getValueFromExp <- function(x) {
print(x)
if (toupper(x) == "H") { x <- 10^2 }
else if (toupper(x) == "K") { x <- 10^3 }
else if (toupper(x) == "M") { x <- 10^6 }
else if (toupper(x) == "B") { x <- 10^9 }
else { x <- NA }
x
}
getValueFromExp <- function(x) {
print(x)
if (toupper(x) == "H") { x <- 10^2 }
else if (toupper(x) == "K") { x <- 10^3 }
else if (toupper(x) == "M") { x <- 10^6 }
else if (toupper(x) == "B") { x <- 10^9 }
else { x <- NA }
x
}
csv$PROPDMGEXPVAL <- sapply(csv, getValueFromExp)
library(ggplot2)
library(reshape2)
setwd("/Users/martin/Dev/datasciencecoursera-repos/assignements/5-represearch-a2")
con <- bzfile("data/repdata-data-csv.csv.bz2", "r")
csv <- read.csv(con)
close(con)
setwd("/Users/martin/Dev/datasciencecoursera-repos/assignements/5-represearch-a2")
library(ggplot2)
library(reshape2)
con <- bzfile("data/repdata-data-csv.csv.bz2", "r")
con <- bzfile("data/repdata-data-StormData.csv.bz2", "r")
csv <- read.csv(con)
csv <- read.csv(con)
csv
library(ggplot2)
library(reshape2)
setwd("/Users/martin/Dev/datasciencecoursera-repos/assignements/5-represearch-a2")
con <- bzfile("data/repdata-data-StormData.csv.bz2", "r")
csv <- read.csv(con)
close(con)
csv$EVTYPE <- tolower(csv$EVTYPE)
typeScores <- aggregate(cbind(csv$INJURIES, csv$FATALITIES) ~ csv$EVTYPE, csv, sum) # 10s
# ignore lines where injured and kill people are 0
fullZero <- typeScores[,2] == 0 & typeScores[,3] == 0
cleanTypeScores <- typeScores[!fullZero,]
names(cleanTypeScores) <- cbind("type", "injuries", "fatalities")
rankInjuries <- order(cleanTypeScores[,2], decreasing=T)
rankFatalities <- order(cleanTypeScores[,3], decreasing=T)
# melt the top 10 killing storm tpes
topTen <- cleanTypeScores[rankFatalities,][1:10,]
# Rebuild factors according to their order after top ten ranking to preserve rank in bar plot
topTen <- within(topTen, type <- factor(type, levels=type))
toPlot <- melt(topTen, "type")
ggplot(toPlot, aes(x=type, y=value, fill=variable)) +
geom_bar(position="dodge") + # identity
theme(axis.text.x = element_text(angle = 60, hjust = 1)) +
labs(title="10 most injuring storm types in US - 1950 to 2011", x="Storm type", y="Number of injured and killed people")
events <- sort(unique(csv$EVTYPE[csv$PROPDMGEXP == "B" | csv$CROPDMGEXP == "B"]))
print(events)
getValueFromExp <- function(x) {
if (toupper(x) == "H") { x <- 10^2 }
else if (toupper(x) == "K") { x <- 10^3 }
else if (toupper(x) == "M") { x <- 10^6 }
else if (toupper(x) == "B") { x <- 10^9 }
else { x <- NA }
x
}
csv$PROPDMGEXPVAL <- sapply(csv, getValueFromExp)
csv$CROPDMGEXPVAL <- sapply(csv$CROPDMGEXP, getValueFromExp)
csv$PROPDMGTOT <- csv$PROPDMG*csv$PROPDMGEXPVAL
csv$CROPDMGTOT <- csv$CROPDMG*csv$CROPDMGEXPVAL
propAndCrop <- aggregate(list(Properties=csv$PROPDMGTOT, Crops=csv$CROPDMGTOT), list(Event=csv$EVTYPE), sum, na.rm=T)
propAndCropSup0 <- propAndCrop[(propAndCrop$Properties+propAndCrop$Crop)>0, ]
c("Total number of events"=length(unique(propAndCrop$Event)), "Number of impacting events"=length(unique(propAndCropSup0$Event)))
#Calculate total amount and percentage for Properties and Crops
propAndCropTot <- colSums(propAndCropSup0[,2:3])
propVsCrop <- data.frame(Damage=names(propAndCropTot), amount=propAndCropTot)
propVsCrop <- cbind(propVsCrop, percent=paste(round(propVsCrop$amount/sum(propVsCrop$amount), 3)*100,"%"))
ggplot(propVsCrop, aes(x = "", y = amount, fill = Damage)) +
geom_bar(stat = "identity", width = 1) +
geom_text(aes(y = amount/2 + c(0, cumsum(amount)[-length(amount)]), label = percent), size=8) +
coord_polar(theta = "y") +
labs(y="", x="") +
ggtitle(expression(atop("Distribution of total amount of damages (in US$)",
atop(italic("for all type of events accross the United States (1950-2011)"), ""))))
table(csv$PROPDMGEXPVAL)
summary(csv$PROPDMGEXPVAL)
View(csv)
getValueFromExp <- function(x) {
print(x)
if (toupper(x) == "H") { x <- 10^2 }
else if (toupper(x) == "K") { x <- 10^3 }
else if (toupper(x) == "M") { x <- 10^6 }
else if (toupper(x) == "B") { x <- 10^9 }
else { x <- NA }
x
}
csv$PROPDMGEXPVAL <- sapply(csv, getValueFromExp)
getValueFromExp <- function(x) {
if (toupper(x) == "H") { x <- 10^2 }
else if (toupper(x) == "K") { x <- 10^3 }
else if (toupper(x) == "M") { x <- 10^6 }
else if (toupper(x) == "B") { x <- 10^9 }
else { x <- NA }
x
}
csv$PROPDMGEXPVAL <- sapply(csv$PROPDMGEXP, getValueFromExp)
csv$CROPDMGEXPVAL <- sapply(csv$CROPDMGEXP, getValueFromExp)
csv$PROPDMGTOT <- csv$PROPDMG*csv$PROPDMGEXPVAL
csv$CROPDMGTOT <- csv$CROPDMG*csv$CROPDMGEXPVAL
propAndCrop <- aggregate(list(Properties=csv$PROPDMGTOT, Crops=csv$CROPDMGTOT), list(Event=csv$EVTYPE), sum, na.rm=T)
propAndCropSup0 <- propAndCrop[(propAndCrop$Properties+propAndCrop$Crop)>0, ]
c("Total number of events"=length(unique(propAndCrop$Event)), "Number of impacting events"=length(unique(propAndCropSup0$Event)))
#Calculate total amount and percentage for Properties and Crops
propAndCropTot <- colSums(propAndCropSup0[,2:3])
propVsCrop <- data.frame(Damage=names(propAndCropTot), amount=propAndCropTot)
propVsCrop <- cbind(propVsCrop, percent=paste(round(propVsCrop$amount/sum(propVsCrop$amount), 3)*100,"%"))
ggplot(propVsCrop, aes(x = "", y = amount, fill = Damage)) +
geom_bar(stat = "identity", width = 1) +
geom_text(aes(y = amount/2 + c(0, cumsum(amount)[-length(amount)]), label = percent), size=8) +
coord_polar(theta = "y") +
labs(y="", x="") +
ggtitle(expression(atop("Distribution of total amount of damages (in US$)",
atop(italic("for all type of events accross the United States (1950-2011)"), ""))))
library(manipulate)
myPlot <- function(s) {
plot(cars$dist - mean(cars$dist), cars$speed - mean(cars$speed))
abline(0, s)
}
manipulate(myPlot, s = slider(0, 2, step = 0.1))
manipulate(myPlot, s = slider(0, 2, step = 0.1))
manipulate(myPlot(s), s = slider(0, 2, step = 0.1))
dTable(airquality, sPaginationType = "full_numbers")
runApp("/Users/martin/Dev/datasciencecoursera-repos/courses/09_DevelopingDataProducts/shiny/inputApp")
library(shiny)
library(shiny)
install.packages("shiny")
library(shiny)
runApp("/Users/martin/Dev/datasciencecoursera-repos/courses/09_DevelopingDataProducts/shiny/inputApp")
install.packages("rCharts")
library(rCharts)
install.packages("rCharts")
require(devtools)
install_github('rCharts', 'ramnathv')
install.packages("devtools")
require(devtools)
install_github('rCharts', 'ramnathv')
fit = lm(mtcars$wt ~ mtcars$mpg)
fit
plot(fit)
imi = means(mtcars$wt)
imi = mean(mtcars$wt)
predict(fit, imi)
sumCoef <- summary(fit)$coefficients
sumCoef
fit $df
fit$df
qt(.975)
qt(.975, df=Inf)
p1 <- predict(fit, imi, interval = ("confidence"))
p1
imi
fit$df
library(UsingR); data(diamond)
y <- diamond$price; x <- diamond$carat; n <- length(y)
install.packages("UsingR")
library(UsingR); data(diamond)
y <- diamond$price; x <- diamond$carat; n <- length(y)
fit <- lm(y ~ x);
plot(x, y, frame=FALSE,xlab="Carat",ylab="Dollars",pch=21,col="black", bg="lightblue", cex=2)
abline(fit, lwd = 2)
min(x)
p1 <- predict(fit, data.frame(imi)
, interval = ("confidence"))
xVals <- seq(min(x), max(x), by = .01) # ticks on x
xVals
newdata <- data.frame(x = xVals)
p1 <- predict(fit, newdata, interval = ("confidence"))
p1
plot(x, y, frame=FALSE,xlab="Carat",ylab="Dollars",pch=21,col="black", bg="lightblue", cex=2
xlim=c(min(x), max(x)*3)
)
plot(x, y, frame=FALSE,xlab="Carat",ylab="Dollars",pch=21,col="black", bg="lightblue", cex=2,
xlim=c(min(x), max(x)*3)
)
abline(fit, lwd = 2)
lines(xVals, p1[,2]); lines(xVals, p1[,3])
plot(x, y, frame=FALSE,xlab="Carat",ylab="Dollars",pch=21,col="black", bg="lightblue", cex=2
#,xlim=c(min(x), max(x)*3)
)
abline(fit, lwd = 2)
lines(xVals, p1[,2]); lines(xVals, p1[,3])
fit = lm(mtcars$mpg ~ mtcars$wt)
p1 <- predict(fit, data.frame(imi), interval = ("confidence"))
size(mtcars$mpg)
length(mtcars$mpg)
length(mtcars$wt)
length(x)
length(xVals)
p1 <- predict(fit, data.frame(x=imi), interval = ("confidence"))
newdata = data.frame(x=imi)
p1 <- predict(fit, newdata, interval = ("confidence"))
p1
fit
cfit = lm(cy ~ cx)
newdata = data.frame(cx=cxm)
p1 <- predict(cfit, newdata, interval = ("confidence"))
cx = mtcars$wt
cy = mtcars$mpg
cxm = mean(mtcars$wt)
cfit = lm(cy ~ cx)
sumCoef <- summary(cfit)$coefficients
newdata = data.frame(cx=cxm)
p1 <- predict(cfit, newdata, interval = ("confidence"))
p1
# The 95% confidence interval for the slope is the estimated coefficient (7.0595) Â± two standard errors (0.9776).
confint(cfit, 'body.weight', level=0.95)
confint(cfit, 'cx', level=0.95)
p1 <- predict(cfit, newdata, interval = ("confidence"), level = 0.95)
p1
p1 <- predict(cfit, newdata, interval = ("confidence"), level = 0.95)
p1
coplot(mpg ~ disp | as.factor(cyl), data = mtcars,
panel = panel.smooth, rows = 1)
pred <- predict(cfit, newdata, interval = ("confidence"), level = 0.95)
plot(cx, cy, pch=21,col="black", bg="lightblue", cex=2)
abline(cfit, lwd = 2)
predict(cfit, data.frame(cx=3), interval = ("confidence"), level = 0.95)
predict(cfit, data.frame(cx=3), interval = ("prediction"), level = 0.95)
summary(cfit)
plot(cx, cy, pch=21,col="black", bg="lightblue", cex=2)
abline(cfit, lwd = 2)
x <- c(0.61, 0.93, 0.83, 0.35, 0.54, 0.16, 0.91, 0.62, 0.62)
y <- c(0.67, 0.84, 0.6, 0.18, 0.85, 0.47, 1.1, 0.65, 0.36)
f = lm(y~x)
f
std(f$residuals)
sd(f$residuals)
cfit
install.packages("devtools")
xmlName(rootNode)
library(XML)
fileUrl <- "http://livres.octo.com/books/feed"
doc <- xmlTreeParse(fileUrl,useInternal=TRUE)
rootNode <- xmlRoot(doc)
xmlName(rootNode)
library(XML)
fileUrl <- "http://livres.octo.com/books/feed"
doc <- xmlTreeParse(fileUrl,useInternal=TRUE)
rootNode <- xmlRoot(doc)
xmlName(rootNode)
install.packages("XML")
library(XML)
fileUrl <- "http://livres.octo.com/books/feed"
doc <- xmlTreeParse(fileUrl,useInternal=TRUE)
rootNode <- xmlRoot(doc)
xmlName(rootNode)
doc
data.frame(doc)
xpathSApply(rootNode,"//name",xmlValue)
rootNode
xpathSApply(rootNode,"//title",xmlValue)
t <- xpathSApply(rootNode,"//title",xmlValue)
write.csv(t, "library.csv")
pwd
getwd
getwd()
library(XML)
fileUrl <- "http://livres.octo.com/books/feed"
doc <- xmlTreeParse(fileUrl,useInternal=TRUE)
rootNode <- xmlRoot(doc)
xmlName(rootNode)
t <- xpathSApply(rootNode,"//title",xmlValue)
write.csv(t, "library-after.csv")
dirCur = "/Users/martin/Dev/vocobox/public/vocobox/dev/r";
dirAur = "/Users/martin/Dev/vocobox/public/aubio-r"
setwd(dirCur)
source(dirAur)
source("./vocoprocess.R")
library(seewave)
library(tuneR)
# try /usr/local/Cellar/aubio/0.4.1/bin/
folderS = "vocobox-java/data/sound/";
folderA = "vocobox-java/data/analyses/";
fileC3 <- paste(folderS, "C3.wav", sep='');
fileDp <- paste(folderS, "dp2.wav", sep='');
fileSinramp <- paste(folderS, "sin-ramp.wav", sep='');
fileBeatbox <- paste(folderS, "beatbox.wav", sep='');
fileDoremi <- paste(folderS, "doremi.wav", sep='');
filePiano <- paste(folderS, "piano.wav", sep='');
fileVoice1 <- paste(folderS, "voice1.wav", sep='');
fileVoice2 <- paste(folderS, "voice2.wav", sep='');
fileVoice3 <- paste(folderS, "voice3.wav", sep='');
analysis(fileDp, folderA, "dp2", show=TRUE)
folderS = "../java/vocobox-apps/data/sound/";
folderA = "../java/vocobox-apps/data/analyses/";
fileC3 <- paste(folderS, "C3.wav", sep='');
fileDp <- paste(folderS, "dp2.wav", sep='');
fileSinramp <- paste(folderS, "sin-ramp.wav", sep='');
fileBeatbox <- paste(folderS, "beatbox.wav", sep='');
fileDoremi <- paste(folderS, "doremi.wav", sep='');
filePiano <- paste(folderS, "piano.wav", sep='');
fileVoice1 <- paste(folderS, "voice1.wav", sep='');
fileVoice2 <- paste(folderS, "voice2.wav", sep='');
fileVoice3 <- paste(folderS, "voice3.wav", sep='');
analysis(fileDp, folderA, "dp2", show=TRUE)
dirCur = "/Users/martin/Dev/vocobox/public/vocobox/dev/r";
dirAur = "/Users/martin/Dev/vocobox/public/aubio-r"
setwd(dirCur)
folderS = "../java/vocobox-apps/data/sound/";
folderA = "../java/vocobox-apps/data/analyses/";
fileC3 <- paste(folderS, "C3.wav", sep='');
fileDp <- paste(folderS, "dp2.wav", sep='');
fileSinramp <- paste(folderS, "sin-ramp.wav", sep='');
fileBeatbox <- paste(folderS, "beatbox.wav", sep='');
fileDoremi <- paste(folderS, "doremi.wav", sep='');
filePiano <- paste(folderS, "piano.wav", sep='');
fileVoice1 <- paste(folderS, "voice1.wav", sep='');
fileVoice2 <- paste(folderS, "voice2.wav", sep='');
fileVoice3 <- paste(folderS, "voice3.wav", sep='');
analysis(fileDp, folderA, "dp2", show=TRUE)
dirAur = "/Users/martin/Dev/vocobox/public/aubio-r/aubio.R"
setwd(dirCur)
source(dirAur)
analysis(fileDp, folderA, "dp2", show=TRUE)
pitch = aubiopitch(filePiano, paste("-p", aubio.pitch.p[6]))#, "-s", -30)) # 4 mcomb 6 yinfft
